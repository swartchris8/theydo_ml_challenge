{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42484c9f-f186-463e-8e5f-7437b1cdcc31",
   "metadata": {},
   "source": [
    "## TheyDo Technical Interview\n",
    "\n",
    "### Finetune a model for:\n",
    "1. summarisation\n",
    "2. translation\n",
    "3. sentiment analysis\n",
    "\n",
    "Based on a dataset from [llama paper](https://arxiv.org/pdf/2302.13971.pdf)\n",
    "\n",
    "Couldn't find a clear summarisation, translation or sentiment analysis dataset from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471e287-01c9-4c90-b566-ae2e0d01e463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37766493-78a2-479a-b2bd-8015d5cbfbd3",
   "metadata": {},
   "source": [
    "### Finetune Summarisation model\n",
    "\n",
    "Which model should we go for?\n",
    "\n",
    "<img src=\"cnn_dailymail_summarisation_landscape.png\">\n",
    "\n",
    "T5 is a great model for any text to text task as such a great fit for summarisation and translationg.\n",
    "I have used T5 before and the small T5 can be finetuned on my Mac.\n",
    "\n",
    "How to measure summarisation performance?\n",
    "\n",
    "ROUGE-1 refers to the overlap of unigrams (each word) between the system and reference summaries\n",
    "ROUGE-2 bigram of above\n",
    "ROUGE-L Longest Common Subsequence (LCS) based score on sentences\n",
    "ROUGE-LSUM Take new lines as sentence boundaries and then LCS score\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Train eval test 5/5/5\n",
    "  \n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_gen_len            =       54.4\n",
    "  eval_loss               =     2.4578\n",
    "  eval_rouge1             =    20.1191\n",
    "  eval_rouge2             =     3.2284\n",
    "  eval_rougeL             =    14.6009\n",
    "  eval_rougeLsum          =    19.8187\n",
    "  eval_runtime            = 0:00:04.03\n",
    "  eval_samples            =          5\n",
    "  eval_samples_per_second =      1.238\n",
    "  eval_steps_per_second   =      0.495\n",
    "\n",
    "Train eval test 2000 500 500\n",
    "\n",
    "***** eval metrics *****\n",
    "\"epoch\": 3.0,\n",
    "\"eval_gen_len\": 59.248,\n",
    "\"eval_loss\": 2.052272081375122,\n",
    "\"eval_rouge1\": 31.186,\n",
    "\"eval_rouge2\": 11.7692,\n",
    "\"eval_rougeL\": 22.3708,\n",
    "\"eval_rougeLsum\": 28.5695,\n",
    "\"eval_runtime\": 2077.82,\n",
    "\"eval_samples\": 500,\n",
    "\"eval_samples_per_second\": 0.241,\n",
    "\"eval_steps_per_second\": 0.06\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af06134-8d70-4c5e-8789-4154bfa99d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/work/theydo_ml_challenge/theydo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finetuned_summarisation\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_summarisation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98514773-5e59-40bb-b3d5-cb3795e54cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"WASHINGTON, June 7 (Reuters) - \n",
    "\n",
    "Ukrainians abandoned inundated homes on Wednesday as floods crested across the south after the destruction of the dam, with Russia and Ukraine trading blame for the disaster.\n",
    "\n",
    "The World Bank will support Ukraine by conducting a rapid assessment of damage and needs after Tuesday's destruction of a huge hydroelectric dam on the front lines between Russian and Ukrainian forces, a top bank official said on Wednesday.\n",
    "\n",
    "Anna Bjerde, the World Bank's managing director for operations, said on Twitter the destruction of the Novo Kakhovka dam had \"many very serious consequences for essential service delivery and the broader environment.\"\n",
    "\n",
    "Ukrainian Prime Minister Denys Shmyhal, also writing on Twitter, said he spoke with Bjerde about the impact of the dam's collapse, and she assured him the World Bank would carry out a rapid assessment of the damage and needs.\n",
    "\n",
    "The World Bank will support Ukraine by conducting a rapid assessment of damage and needs after Tuesday's destruction of a huge hydroelectric dam on the front lines between Russian and Ukrainian forces, a top bank official said on Wednesday.\n",
    "\n",
    "Ukrainians abandoned inundated homes on Wednesday as floods crested across the south after the destruction of the dam, with Russia and Ukraine trading blame for the disaster.\n",
    "\n",
    "Ukraine said the deluge would leave hundreds of thousands of people without access to drinking water, swamp tens of thousands of hectares of agricultural land and turn at least 500,000 hectares deprived of irrigation into \"deserts\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8842f9aa-4424-452a-9575-0250dce3aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7071ec13-fe69-4d25-8052-c735ff643cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Bank will support Ukraine by conducting a rapid assessment of damage and needs. Ukrainians\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/work/theydo_ml_challenge/theydo/lib/python3.11/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(f\"summarize: {example}\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdfacd-e351-4e29-a1b3-3d1d5536c296",
   "metadata": {},
   "source": [
    "Russian and Ukrainian forces on the front lines of conflict have been blamed for the destruction of the Novo Kakhovka dam on Tuesday, causing flooding in Ukraine's southern region and displacing hundreds of thousands of people. The World Bank is providing support by conducting a rapid assessment of damage and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38950f1e-2824-4210-9131-e11de4adbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load saved models and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8acdcf57-3fc9-4645-a596-5aa661517314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finetuned_de-en_translation\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_de-en_translation\")\n",
    "\n",
    "\n",
    "# task_prefix = \"translate German to English: \"\n",
    "task_prefix = \"\"\n",
    "\n",
    "sentences = [\"Das Haus ist wunderbar.\", \"Ich arbeite gerne in NYC.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0b430e-dbc2-4754-9acf-2522c6f79651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The house is wonderful.\n",
      "I like working in NYC.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([f\"{task_prefix}{sentence}\" for sentence in sentences], return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(inputs[\"input_ids\"])\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(tokenizer.decode(outputs[1], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a5806d-e978-47a1-9ed5-70a778d5ef4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  1150,  1925,    56,   380, 11897,    57, 13646,  3607,  4193,\n",
       "           13,  1783,    11,   523,     3,     5, 22849,     7, 13876,    16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119d0e3-2b15-4b5c-820d-b44780a37181",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d484f4e-08d0-43c0-b3d4-a8e4b490a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finetuned-imdb-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finetuned-imdb-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d870bc33-226d-4523-8ec1-76c0851581ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Pirates of the Caribean was a horrible movie.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fe2953b-be37-4a61-a285-e952b557a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 0 tensor([[0.9844, 0.0156]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/nj127lc1663btr53s35_n_fh0000gn/T/ipykernel_71500/4045664043.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = torch.nn.functional.softmax(logits)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def sent_pred(text):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_label = model.config.id2label[predicted_class_id]\n",
    "    probs = torch.nn.functional.softmax(logits)\n",
    "    print(f\"Predicted {predicted_label} {probs}\")\n",
    "\n",
    "sent_pred(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ec9f73d-7f51-44f9-ba49-3fd9fb6c0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 1 tensor([[0.1129, 0.8871]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/nj127lc1663btr53s35_n_fh0000gn/T/ipykernel_71500/4045664043.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = torch.nn.functional.softmax(logits)\n"
     ]
    }
   ],
   "source": [
    "sent_pred(\"Inception was a great movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef58545d-0bf6-4110-a585-857c283ee17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "   11500\n"
     ]
    }
   ],
   "source": [
    "!ls data/aclImdb/train/neg | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a241c7-964d-4aea-ad8b-93d76b657ae9",
   "metadata": {},
   "source": [
    "## Compare OpenAI and finetuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400f28cd-475c-4ab8-a09b-a9402ef8b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cnn_test = pd.read_csv(\"data/cnn_dailymail/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38084a94-4bc9-42c6-9b37-6aab7533d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test = cnn_test.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48da738b-4472-4d6f-9803-7f42806ff15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>64ee7c9eb9f1efbb7da0ce80498434c623615b84</td>\n",
       "      <td>As Zlatan Ibrahimovic famously believes the Wo...</td>\n",
       "      <td>Zlatan Ibrahimovic will line up against former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5cf4682cd03238d5867027ce9492b626cd1ed011</td>\n",
       "      <td>Jameela spent £3,000 on having all her amalgam...</td>\n",
       "      <td>Jameela Jamil, 29, is convinced dental work tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3815d19af18ff22be6ad6095722d7367bb7271af</td>\n",
       "      <td>A paramedic who pretended he was gay to get cl...</td>\n",
       "      <td>Christopher Bridger, 25, attacked three women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>fb207604ffa7e8371c622840445825db8993d4d2</td>\n",
       "      <td>Paris Saint-Germain face Nice on Saturday, hop...</td>\n",
       "      <td>Paris Saint-Germain captain Thiago Silva suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>d25d52c434a13c1df5faa593e8a097d2f501a2b6</td>\n",
       "      <td>(CNN)You know the phrase \"dodging a bullet\"? F...</td>\n",
       "      <td>.50-caliber bullets equipped with optical sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id  \\\n",
       "0   92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1   2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2   91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3   caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4   3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "..                                       ...   \n",
       "95  64ee7c9eb9f1efbb7da0ce80498434c623615b84   \n",
       "96  5cf4682cd03238d5867027ce9492b626cd1ed011   \n",
       "97  3815d19af18ff22be6ad6095722d7367bb7271af   \n",
       "98  fb207604ffa7e8371c622840445825db8993d4d2   \n",
       "99  d25d52c434a13c1df5faa593e8a097d2f501a2b6   \n",
       "\n",
       "                                              article  \\\n",
       "0   Ever noticed how plane seats appear to be gett...   \n",
       "1   A drunk teenage boy had to be rescued by secur...   \n",
       "2   Dougie Freedman is on the verge of agreeing a ...   \n",
       "3   Liverpool target Neto is also wanted by PSG an...   \n",
       "4   Bruce Jenner will break his silence in a two-h...   \n",
       "..                                                ...   \n",
       "95  As Zlatan Ibrahimovic famously believes the Wo...   \n",
       "96  Jameela spent £3,000 on having all her amalgam...   \n",
       "97  A paramedic who pretended he was gay to get cl...   \n",
       "98  Paris Saint-Germain face Nice on Saturday, hop...   \n",
       "99  (CNN)You know the phrase \"dodging a bullet\"? F...   \n",
       "\n",
       "                                           highlights  \n",
       "0   Experts question if  packed out planes are put...  \n",
       "1   Drunk teenage boy climbed into lion enclosure ...  \n",
       "2   Nottingham Forest are close to extending Dougi...  \n",
       "3   Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4   Tell-all interview with the reality TV star, 6...  \n",
       "..                                                ...  \n",
       "95  Zlatan Ibrahimovic will line up against former...  \n",
       "96  Jameela Jamil, 29, is convinced dental work tr...  \n",
       "97  Christopher Bridger, 25, attacked three women ...  \n",
       "98  Paris Saint-Germain captain Thiago Silva suffe...  \n",
       "99  .50-caliber bullets equipped with optical sens...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10c11a0-ad50-47df-9820-511b64534d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7311.92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cnn_test.article.apply(len))*0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466f707e-68eb-4100-bac4-770391ae31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.infer_openai import openai_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73001ce-3090-4640-9d95-e3d518da3240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [08:41<00:00,  5.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "openai_summaries = []\n",
    "articles = list(cnn_test.article)\n",
    "for article in tqdm(articles):\n",
    "    openai_summaries.append(openai_summary(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98beacad-cf97-48cc-8b73-a8595de22bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('openai_summaries.json', 'w') as f:\n",
    "    json.dump(openai_summaries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d5f407-3643-4c64-bc14-7732bbfed7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/nj127lc1663btr53s35_n_fh0000gn/T/ipykernel_85428/2404747185.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cnn_test[\"openai\"] = openai_summaries\n"
     ]
    }
   ],
   "source": [
    "cnn_test[\"openai\"] = openai_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c66961d5-9d46-4814-accf-4b334a60b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/work/theydo_ml_challenge/theydo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c382a4e6-fc57-4768-a198-93f1889e987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_results = rouge.compute(predictions=cnn_test[\"openai\"], references=cnn_test[\"highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12323a53-cf9b-4a62-bb9f-9ad5b9f10221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/Users/chris/work/theydo_ml_challenge/theydo/lib/python3.11/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  4%|█▋                                         | 4/100 [00:00<00:22,  4.23it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████| 100/100 [00:34<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from api.infer import summarise\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "fine_summaries = []\n",
    "articles = list(cnn_test.article)\n",
    "for article in tqdm(articles):\n",
    "    fine_summaries.append(summarise(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29599f39-9c69-40be-906f-084d1a68ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/nj127lc1663btr53s35_n_fh0000gn/T/ipykernel_85428/2975420398.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cnn_test[\"finetune\"] = fine_summaries\n"
     ]
    }
   ],
   "source": [
    "cnn_test[\"finetune\"] = fine_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69d5e25e-6bbe-4722-a5e8-d9dcd0f02da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_results = rouge.compute(predictions=cnn_test[\"finetune\"], references=cnn_test[\"highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62677201-17a5-47fa-a20a-de2380ce566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI {'rouge1': 0.3711652739208089, 'rouge2': 0.12991879419704758, 'rougeL': 0.23570574188914356, 'rougeLsum': 0.304950388468087}\n",
      "Finetune {'rouge1': 0.23731288238512083, 'rouge2': 0.11321663348202815, 'rougeL': 0.20167088618817003, 'rougeLsum': 0.2204555556945117}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"OpenAI {openai_results}\n",
    "Finetune {fine_results}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb9838-5493-4dc9-99ec-47a388fab20a",
   "metadata": {},
   "source": [
    "OpenAI has much higher rouge1 and rougeLsum showing that it uses 37% of the words from the target phrases and having a good long term similarities as well from high rougeLsum\n",
    "\n",
    "**OpenAI wins for SUMMARISATION with a cost of $1.53**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eeff52e-bea1-4eb8-9b2e-a3abdc4d638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "imdb_neg = Path(\"data/aclImdb/test/neg/\")\n",
    "counter = 50\n",
    "for neg in imdb_neg.iterdir():\n",
    "    if neg.is_file():\n",
    "        counter -= 1\n",
    "        with open(neg) as fh:\n",
    "            text = fh.read()\n",
    "        texts.append(text)\n",
    "        labels.append(0)\n",
    "        if counter == 0:\n",
    "            break\n",
    "            \n",
    "imdb_pos = Path(\"data/aclImdb/test/pos/\")\n",
    "counter = 50\n",
    "for pos in imdb_pos.iterdir():\n",
    "    if pos.is_file():\n",
    "        counter -= 1\n",
    "        with open(pos) as fh:\n",
    "            text = fh.read()\n",
    "        texts.append(text)\n",
    "        labels.append(1)\n",
    "        if counter == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad7b7647-f633-426e-ac5a-8ef06947a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test = pd.DataFrame({\"texts\": texts, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "489a8ed9-f7c4-4966-8de8-17bfb065473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [01:48<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "from api.infer_openai import openai_sentiment\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai_sentiments = []\n",
    "imdb_reviews = list(imdb_test.texts)\n",
    "for review in tqdm(imdb_reviews):\n",
    "    openai_sentiments.append(openai_sentiment(review))\n",
    "\n",
    "import json\n",
    "with open('openai_sentiment.json', 'w') as f:\n",
    "    json.dump(openai_sentiments, f)\n",
    "\n",
    "imdb_test[\"openai\"] = openai_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c52e9578-3d68-47e8-a1d5-d0b8c547ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(\"finetuned-imdb-bert\", truncation=True)\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"finetuned-imdb-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a0f3d07-49d0-42f4-8a70-ce1256a7711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text: str, with_prob=False) -> str:\n",
    "    inputs = sentiment_tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        logits = sentiment_model(**inputs).logits\n",
    "    \n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_label = sentiment_model.config.id2label[predicted_class_id]\n",
    "    probs = torch.nn.functional.softmax(logits)\n",
    "    \n",
    "    if with_prob:\n",
    "        return {\"label\": predicted_label, \"probability\": probs}\n",
    "    else:\n",
    "        return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb006dd1-adc3-4076-a8ab-f2267aebdeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b838ef3-b0ab-4a3d-af9f-813d3b33c382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/var/folders/6v/nj127lc1663btr53s35_n_fh0000gn/T/ipykernel_85428/1222808470.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = torch.nn.functional.softmax(logits)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 16.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# from api.infer import sentiment\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "fine_sentiment = []\n",
    "imdb_reviews = list(imdb_test.texts)\n",
    "for review in tqdm(imdb_reviews):\n",
    "    fine_sentiment.append(sentiment(review[:508]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79355e5f-e8e4-4ec6-87a2-3ddc95b7f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test[\"fine\"] = fine_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc07339-82bf-49d5-a58a-e471d1a3125c",
   "metadata": {},
   "source": [
    "Open AI is not so good following instructions the labels are a bit noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69902aef-a1f8-4ff8-8c1e-9725929f0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   \\n\\n1\n",
       "1                   \\n\\n0\n",
       "2                   \\n\\n0\n",
       "3                   \\n\\n0\n",
       "4                   \\n\\n0\n",
       "5                   \\n\\n0\n",
       "6                   \\n\\n0\n",
       "7                 \\n\\n{0}\n",
       "8                   \\n\\n0\n",
       "9     <br /><br />\\n**0**\n",
       "Name: openai, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test.openai.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d38d8dfb-6d9d-4226-9375-770f9d166300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_openai_imdb(label: str) -> str:\n",
    "    if \"0\" in label:\n",
    "        return 0\n",
    "    elif \"1\" in label:\n",
    "        return 1\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2118cff9-a65a-4bcb-aae8-575a0ad39e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test[\"openai\"] = imdb_test.openai.apply(clean_openai_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f6717-f4f7-4e41-85ed-25cae49e6c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7341a662-d854-404b-af0d-d4b4a19a92c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test.labels.iloc[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b24752d-cab7-4640-8467-b65cee1d7d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI SENTIMENT ANALYSIS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        50\n",
      "    positive       0.91      0.96      0.93        50\n",
      "\n",
      "   micro avg       0.93      0.92      0.92       100\n",
      "   macro avg       0.93      0.92      0.92       100\n",
      "weighted avg       0.93      0.92      0.92       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['negative', 'positive']\n",
    "print(\"OpenAI SENTIMENT ANALYSIS\")\n",
    "print(classification_report(imdb_test[\"labels\"], imdb_test[\"openai\"], target_names=target_names, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4723ad7-30f3-45f3-b713-37a9c2050044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT SENTIMENT ANALYSIS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.88      0.79        50\n",
      "    positive       0.85      0.66      0.74        50\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.78      0.77      0.77       100\n",
      "weighted avg       0.78      0.77      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT SENTIMENT ANALYSIS\")\n",
    "print(classification_report(imdb_test[\"labels\"], imdb_test[\"fine\"], target_names=target_names, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389d031-7af1-4311-bc70-fc064d22d221",
   "metadata": {},
   "source": [
    "**OpenAI wins for sentiment analysis superior precision for the cost of $0.29 for a 100 elements**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b269d570-7708-4f95-933d-7ecd8fab31c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset wmt16 (/Users/chris/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  4.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wmt16\", 'de-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21150e3a-5549-4095-b595-ab2584a21773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.StringScalar: 'Obama empfängt Netanyahu'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 100\n",
    "german_docs = []\n",
    "for ger_doc in dataset[\"test\"].data[\"translation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4bc70cfc-42a1-493c-94ac-0afdfb306752",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "german_sents = []\n",
    "english_sents = []\n",
    "for e in dataset[\"test\"].data[\"translation\"][:100]:\n",
    "    german_sents.append(e[0])\n",
    "    english_sents.append(e[1])\n",
    "    counter += 1\n",
    "    if counter == 100:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d8adef2-3a0f-4c51-a468-49af7a2bae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_df = pd.DataFrame({\"de\": german_sents, \"en\": english_sents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9e9926f-dc7a-4757-a462-286f5ef798d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [03:49<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from api.infer_openai import openai_translate_german_to_english\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai_translations = []\n",
    "german_sents = list(translation_df.de)\n",
    "for german_sent in tqdm(german_sents):\n",
    "    openai_translations.append(openai_translate_german_to_english(german_sent))\n",
    "\n",
    "import json\n",
    "with open('openai_translations.json', 'w') as f:\n",
    "    json.dump(openai_translations, f)\n",
    "\n",
    "translation_df[\"openai\"] = openai_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ffd1f482-29ab-4437-8648-c9d8e8a80937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/work/theydo_ml_challenge/theydo/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finetuned_de-en_translation\")\n",
    "translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_de-en_translation\")\n",
    "\n",
    "def translate_german_to_english(text: str, task_prefix = \"\") -> str:\n",
    "    inputs = tokenizer([f\"{task_prefix}{sentence}\" for sentence in [text]], return_tensors=\"pt\", padding=True)\n",
    "    outputs = translation_model.generate(inputs[\"input_ids\"])\n",
    "    # print(outputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f9131f10-2fb1-4c9e-97ed-da19567013f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/work/theydo_ml_challenge/theydo/lib/python3.11/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Obama receives Netanyahu'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_german_to_english(\"Obama empfängt Netanyahu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "803a11a9-efba-4cfa-a2d3-e00e9cec9ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:59<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "fine_translations = []\n",
    "german_sents = list(translation_df.de)\n",
    "for german_sent in tqdm(german_sents):\n",
    "    fine_translations.append(translate_german_to_english(german_sent))\n",
    "\n",
    "translation_df[\"fine\"] = fine_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b017fd8f-2486-4976-8e8c-a5bb1826e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_translations.json\") as fh:\n",
    "    openai_translations = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3066b27c-229f-4d70-88c6-9a90383fcd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_df[\"openai\"] = translation_df[\"openai\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5814193f-88fc-4c15-b906-e58ac196f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.94k/5.94k [00:00<00:00, 14.5MB/s]\n",
      "Downloading extra modules: 4.07kB [00:00, 6.79MB/s]                             \n",
      "Downloading extra modules: 100%|███████████| 3.34k/3.34k [00:00<00:00, 3.90MB/s]\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb3314-7cc5-4d84-9fee-45c945e32de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "57419371-45be-4050-80ec-a50675014745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI {'bleu': 0.5223381400841746, 'precisions': [0.7807139545665276, 0.5785123966942148, 0.45477772100153296, 0.362412493268713], 'brevity_penalty': 1.0, 'length_ratio': 1.0160150730098916, 'translation_length': 2157, 'reference_length': 2123}\n",
      "FINETUNE RESULTS\n",
      "{'bleu': 0.45434115198395, 'precisions': [0.7358405074762121, 0.5140009492168961, 0.38365719980069757, 0.29365495542737285], 'brevity_penalty': 1.0, 'length_ratio': 1.0395666509656147, 'translation_length': 2207, 'reference_length': 2123}\n"
     ]
    }
   ],
   "source": [
    "openai_results = bleu.compute(predictions=translation_df[\"openai\"], references=[[str(e)] for e in translation_df[\"en\"]])\n",
    "fine_results = bleu.compute(predictions=translation_df[\"fine\"], references=[[str(e)] for e in translation_df[\"en\"]])\n",
    "print(f\"\"\"OPENAI {openai_results}\n",
    "FINETUNE RESULTS\n",
    "{fine_results}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7385358-afd7-4a68-8988-619fcf3b03f7",
   "metadata": {},
   "source": [
    "***OpenAI wins for German to English translation for the cost of 0.20$ for 100 sentences***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
