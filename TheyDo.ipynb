{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42484c9f-f186-463e-8e5f-7437b1cdcc31",
   "metadata": {},
   "source": [
    "## TheyDo Technical Interview\n",
    "\n",
    "### Finetune a model for:\n",
    "1. summarisation\n",
    "2. translation\n",
    "3. sentiment analysis\n",
    "\n",
    "Based on a dataset from [llama paper](https://arxiv.org/pdf/2302.13971.pdf)\n",
    "\n",
    "Couldn't find a clear summarisation, translation or sentiment analysis dataset from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471e287-01c9-4c90-b566-ae2e0d01e463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37766493-78a2-479a-b2bd-8015d5cbfbd3",
   "metadata": {},
   "source": [
    "### Finetune Summarisation model\n",
    "\n",
    "Which model should we go for?\n",
    "\n",
    "<img src=\"cnn_dailymail_summarisation_landscape.png\">\n",
    "\n",
    "T5 is a great model for any text to text task as such a great fit for summarisation and translationg.\n",
    "I have used T5 before and the small T5 can be finetuned on my Mac.\n",
    "\n",
    "How to measure summarisation performance?\n",
    "\n",
    "ROUGE-1 refers to the overlap of unigrams (each word) between the system and reference summaries\n",
    "ROUGE-2 bigram of above\n",
    "ROUGE-L Longest Common Subsequence (LCS) based score on sentences\n",
    "ROUGE-LSUM Take new lines as sentence boundaries and then LCS score\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Train eval test 5/5/5\n",
    "  \n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_gen_len            =       54.4\n",
    "  eval_loss               =     2.4578\n",
    "  eval_rouge1             =    20.1191\n",
    "  eval_rouge2             =     3.2284\n",
    "  eval_rougeL             =    14.6009\n",
    "  eval_rougeLsum          =    19.8187\n",
    "  eval_runtime            = 0:00:04.03\n",
    "  eval_samples            =          5\n",
    "  eval_samples_per_second =      1.238\n",
    "  eval_steps_per_second   =      0.495\n",
    "\n",
    "Train eval test 2000 500 500\n",
    "\n",
    "***** eval metrics *****\n",
    "\"epoch\": 3.0,\n",
    "\"eval_gen_len\": 59.248,\n",
    "\"eval_loss\": 2.052272081375122,\n",
    "\"eval_rouge1\": 31.186,\n",
    "\"eval_rouge2\": 11.7692,\n",
    "\"eval_rougeL\": 22.3708,\n",
    "\"eval_rougeLsum\": 28.5695,\n",
    "\"eval_runtime\": 2077.82,\n",
    "\"eval_samples\": 500,\n",
    "\"eval_samples_per_second\": 0.241,\n",
    "\"eval_steps_per_second\": 0.06\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af06134-8d70-4c5e-8789-4154bfa99d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tst-summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"tst-summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98514773-5e59-40bb-b3d5-cb3795e54cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"WASHINGTON, June 7 (Reuters) - \n",
    "\n",
    "Ukrainians abandoned inundated homes on Wednesday as floods crested across the south after the destruction of the dam, with Russia and Ukraine trading blame for the disaster.\n",
    "\n",
    "The World Bank will support Ukraine by conducting a rapid assessment of damage and needs after Tuesday's destruction of a huge hydroelectric dam on the front lines between Russian and Ukrainian forces, a top bank official said on Wednesday.\n",
    "\n",
    "Anna Bjerde, the World Bank's managing director for operations, said on Twitter the destruction of the Novo Kakhovka dam had \"many very serious consequences for essential service delivery and the broader environment.\"\n",
    "\n",
    "Ukrainian Prime Minister Denys Shmyhal, also writing on Twitter, said he spoke with Bjerde about the impact of the dam's collapse, and she assured him the World Bank would carry out a rapid assessment of the damage and needs.\n",
    "\n",
    "The World Bank will support Ukraine by conducting a rapid assessment of damage and needs after Tuesday's destruction of a huge hydroelectric dam on the front lines between Russian and Ukrainian forces, a top bank official said on Wednesday.\n",
    "\n",
    "Ukrainians abandoned inundated homes on Wednesday as floods crested across the south after the destruction of the dam, with Russia and Ukraine trading blame for the disaster.\n",
    "\n",
    "Ukraine said the deluge would leave hundreds of thousands of people without access to drinking water, swamp tens of thousands of hectares of agricultural land and turn at least 500,000 hectares deprived of irrigation into \"deserts\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8842f9aa-4424-452a-9575-0250dce3aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7071ec13-fe69-4d25-8052-c735ff643cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Bank will support Ukraine by conducting a rapid assessment of damage and needs. Ukrainians\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(f\"summarize: {example}\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38950f1e-2824-4210-9131-e11de4adbfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8acdcf57-3fc9-4645-a596-5aa661517314",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "sentences = [\"The house is wonderful.\", \"I like to work in NYC.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d0b430e-dbc2-4754-9acf-2522c6f79651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Haus ist wunderbar.\n",
      "Ich arbeite gerne in NYC.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([f\"{task_prefix}{sentence}\" for sentence in sentences], return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(inputs[\"input_ids\"])\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(tokenizer.decode(outputs[1], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a5806d-e978-47a1-9ed5-70a778d5ef4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  1150,  1925,    56,   380, 11897,    57, 13646,  3607,  4193,\n",
       "           13,  1783,    11,   523,     3,     5, 22849,     7, 13876,    16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d484f4e-08d0-43c0-b3d4-a8e4b490a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"test-sent-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"test-sent-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d870bc33-226d-4523-8ec1-76c0851581ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Pirates of the Caribean was a horrible movie.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fe2953b-be37-4a61-a285-e952b557a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ec9f73d-7f51-44f9-ba49-3fd9fb6c0934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef58545d-0bf6-4110-a585-857c283ee17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9ae44-651d-425e-9d17-311b8a372d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
